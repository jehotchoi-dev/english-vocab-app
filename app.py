import streamlit as st
import pandas as pd
import requests
from gtts import gTTS
import tempfile
import os
import uuid
from io import StringIO, BytesIO
import time

# ğŸ¯ êµ¬ê¸€ ì‹œíŠ¸ ì£¼ì†Œ ì„¤ì • (ì—¬ê¸°ë§Œ ìˆ˜ì •í•˜ë©´ ë©ë‹ˆë‹¤!)
GOOGLE_SHEET_URL = "https://docs.google.com/spreadsheets/d/e/2PACX-1vTZltgfm_yfhVNBHaK8Aj1oQArXZhn8woXNn9hM_NIjryHQeVgkt3KP3xEx6h-IlHVFFlbxgQS2l5A5/pub?output=csv"

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ“ ì˜ì–´ ë‹¨ì–´ì¥",
    page_icon="ğŸ“š",
    layout="wide"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'vocab_data' not in st.session_state:
    st.session_state.vocab_data = None
if 'current_index' not in st.session_state:
    st.session_state.current_index = 0
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False

def convert_sheet_url(original_url):
    """êµ¬ê¸€ ì‹œíŠ¸ ë§í¬ë¥¼ CSV í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    url = original_url.strip()
    if 'output=csv' in url:
        return url
    if 'pubhtml' in url:
        return url.replace('pubhtml', 'pub?output=csv')
    if '/edit' in url:
        return url.split('/edit')[0] + '/export?format=csv'
    return url

@st.cache_data(ttl=3600)
def load_csv_data(url):
    """êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ CSV ë°ì´í„° ì½ê¸° (ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)"""
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        response = requests.get(url, headers=headers, timeout=20)
        response.raise_for_status()
        
        # BOM ì œê±° í›„ UTF-8ë¡œ ê°•ì œ ë””ì½”ë”©
        content = response.content
        if content.startswith(b'\xef\xbb\xbf'):
            content = content[3:]  # BOM ì œê±°
        
        # BytesIOë¥¼ ì‚¬ìš©í•´ ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ ì§ì ‘ pandasì— ì „ë‹¬í•˜ê³  UTF-8 ëª…ì‹œ
        try:
            df = pd.read_csv(BytesIO(content), encoding='utf-8')
            return df, "UTF-8"
        except UnicodeDecodeError:
            # UTF-8 ì‹¤íŒ¨ ì‹œ ë‹¤ë¥¸ ì¸ì½”ë”©ë“¤ ì‹œë„
            encodings = ['utf-8-sig', 'cp949', 'euc-kr']
            for encoding in encodings:
                try:
                    df = pd.read_csv(BytesIO(content), encoding=encoding)
                    return df, encoding
                except (UnicodeDecodeError, pd.errors.ParserError):
                    continue
            
            # ëª¨ë“  ì¸ì½”ë”© ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì²˜ë¦¬
            return None, "encoding_error"
            
    except Exception as e:
        return None, str(e)

def fix_broken_korean(text):
    """ê¹¨ì§„ í•œê¸€ íŒ¨í„´ ë³µêµ¬"""
    if not isinstance(text, str):
        return text
    
    # ì¼ë°˜ì ì¸ ê¹¨ì§„ í•œê¸€ íŒ¨í„´ë“¤ì„ ì •ìƒ í•œê¸€ë¡œ ë³µêµ¬
    korean_fixes = {
        'Ã¬Â¬ÃªÂ³Â¼': 'ì‚¬ê³¼', 'Ã¬Â±': 'ì±…', 'Ã­Ã«Â³ÂµÃ­': 'í–‰ë³µí•œ', 'Ã«Â¬Â¼': 'ë¬¼',
        'ÃªÂ³ÂµÃ«Â¶Ã­Ã«Â¤': 'ê³µë¶€í•˜ë‹¤', 'Ã¬Ã¬Â´': 'ì˜ì–´', 'Ã­ÃªÂµÂ­Ã¬Â´': 'í•œêµ­ì–´',
        'Ã¬Â»Â´Ã­Â¨Ã­Â°': 'ì»´í“¨í„°', 'Ã­ÃªÂµ': 'í•™êµ', 'Ã¬Â§': 'ì§‘', 'Ã¬Â°Â¨': 'ì°¨',
        'Ã¬Â¬Ã«': 'ì‚¬ëŒ', 'Ã¬ÃªÂ°': 'ì‹œê°„', 'ÃªÂ³ÂµÃ«Â¶': 'ê³µë¶€', 'Ã­Ã¬Âµ': 'í•™ìŠµ',
        'Ã¬Ã«Â¦Ã«Â¤Ã¬Â´': 'ì•„ë¦„ë‹¤ìš´', 'Ã¬Â¢Ã¬': 'ì¢‹ì€'
    }
    
    for broken, fixed in korean_fixes.items():
        text = text.replace(broken, fixed)
    
    return text

def generate_audio(text, lang):
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ë°˜í™˜"""
    if not text or str(text).strip() == "":
        return None
    
    try:
        tts = gTTS(text=str(text).strip(), lang=lang)
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
        tts.save(temp_file.name)
        
        with open(temp_file.name, 'rb') as f:
            audio_bytes = f.read()
        
        os.unlink(temp_file.name)
        return audio_bytes
        
    except Exception as e:
        st.error(f"ìŒì„± ìƒì„± ì˜¤ë¥˜: {e}")
        return None

# ğŸš€ ì•± ì‹œì‘ ì‹œ ìë™ìœ¼ë¡œ ë°ì´í„° ë¡œë“œ
def auto_load_data():
    """ì•± ì‹œì‘ ì‹œ ìë™ìœ¼ë¡œ êµ¬ê¸€ ì‹œíŠ¸ ë°ì´í„° ë¡œë“œ"""
    if not st.session_state.data_loaded:
        with st.spinner("ğŸ“¡ êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ë‹¨ì–´ ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            csv_url = convert_sheet_url(GOOGLE_SHEET_URL)
            result = load_csv_data(csv_url)
            
            if isinstance(result, tuple):
                data, encoding_info = result
            else:
                data, encoding_info = result, "unknown"
            
            if data is not None:
                # ì»¬ëŸ¼ ì •ê·œí™”
                column_mapping = {}
                for col in data.columns:
                    normalized_col = str(col).strip().lower()
                    if normalized_col in ['word', 'words', 'ë‹¨ì–´']:
                        column_mapping['Word'] = col
                    elif normalized_col in ['meaning', 'meanings', 'ëœ»']:
                        column_mapping['Meaning'] = col
                
                if 'Word' in column_mapping and 'Meaning' in column_mapping:
                    data = data.rename(columns={
                        column_mapping['Word']: 'Word',
                        column_mapping['Meaning']: 'Meaning'
                    })[['Word', 'Meaning']].copy()
                    
                    # ê¹¨ì§„ í•œê¸€ ë³µêµ¬ ì‹œë„
                    data['Word'] = data['Word'].apply(fix_broken_korean)
                    data['Meaning'] = data['Meaning'].apply(fix_broken_korean)
                    
                    data = data.dropna().reset_index(drop=True)
                    data = data[data['Word'].str.strip() != ''].reset_index(drop=True)
                    
                    st.session_state.vocab_data = data
                    st.session_state.current_index = 0
                    st.session_state.data_loaded = True
                    
                    st.success(f"âœ… ìë™ìœ¼ë¡œ {len(data)}ê°œ ë‹¨ì–´ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤! ({encoding_info} ì¸ì½”ë”©)")
                    return True
                else:
                    st.error("âŒ êµ¬ê¸€ ì‹œíŠ¸ì— 'Word'ì™€ 'Meaning' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤!")
                    return False
            else:
                st.error(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {encoding_info}")
                st.info("êµ¬ê¸€ ì‹œíŠ¸ê°€ 'ì›¹ì— ê²Œì‹œ' ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
                return False
    return True

# ë©”ì¸ UI
st.title("ğŸ“ ì˜ì–´ ë‹¨ì–´ì¥ í•™ìŠµ ì‹œìŠ¤í…œ")
st.markdown("**êµ¬ê¸€ ì‹œíŠ¸ ìë™ ì—°ê²° ë²„ì „ - ë°”ë¡œ ì‹œì‘í•˜ì„¸ìš”!**")

# ğŸš€ ìë™ ë°ì´í„° ë¡œë“œ ì‹¤í–‰
auto_load_data()

st.markdown("---")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    # í˜„ì¬ ì—°ê²°ëœ ì‹œíŠ¸ ì •ë³´ í‘œì‹œ
    with st.expander("ğŸ“‹ ì—°ê²°ëœ êµ¬ê¸€ ì‹œíŠ¸", expanded=False):
        st.code(GOOGLE_SHEET_URL[:60] + "...", language=None)
        st.caption("ğŸ’¡ ì‹œíŠ¸ ì£¼ì†ŒëŠ” ì½”ë“œì— í•˜ë“œì½”ë”©ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
        
        # ìˆ˜ë™ ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
        if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨", use_container_width=True):
            # ìºì‹œ í´ë¦¬ì–´ í›„ ë‹¤ì‹œ ë¡œë“œ
            st.cache_data.clear()
            st.session_state.data_loaded = False
            st.rerun()
    
    # í•™ìŠµ ì„¤ì •
    if st.session_state.vocab_data is not None:
        with st.expander("ğŸ¯ í•™ìŠµ ì„¤ì •", expanded=True):
            if st.button("ğŸ”€ ìˆœì„œ ì„ê¸°", use_container_width=True):
                st.session_state.vocab_data = st.session_state.vocab_data.sample(frac=1).reset_index(drop=True)
                st.session_state.current_index = 0
                st.success("ìˆœì„œë¥¼ ì„ì—ˆìŠµë‹ˆë‹¤!")
            
            # ë¹ ë¥¸ ì´ë™
            if len(st.session_state.vocab_data) > 0:
                st.markdown("**ğŸ¯ ë¹ ë¥¸ ì´ë™:**")
                quick_jump = st.selectbox(
                    "ë‹¨ì–´ ì„ íƒ:",
                    range(len(st.session_state.vocab_data)),
                    format_func=lambda x: f"{x+1}. {st.session_state.vocab_data.iloc[x]['Word']}",
                    index=st.session_state.current_index
                )
                if quick_jump != st.session_state.current_index:
                    st.session_state.current_index = quick_jump
                    st.rerun()

# ë©”ì¸ ì˜ì—­
if st.session_state.vocab_data is not None:
    data = st.session_state.vocab_data
    current_idx = st.session_state.current_index
    
    # ì§„í–‰ë¥  í‘œì‹œ
    progress = (current_idx + 1) / len(data)
    st.progress(progress)
    st.markdown(f"**ğŸ“Š ì§„í–‰ë¥ : {current_idx + 1}/{len(data)} ({progress*100:.1f}%)**")
    
    # í˜„ì¬ ë‹¨ì–´ í‘œì‹œ
    if current_idx < len(data):
        word_data = data.iloc[current_idx]
        
        # ë‹¨ì–´ ì¹´ë“œ ìŠ¤íƒ€ì¼
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 30px;
            border-radius: 15px;
            margin: 20px 0;
            text-align: center;
            color: white;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        ">
            <h1 style="margin: 0; font-size: 3em; text-shadow: 2px 2px 4px rgba(0,0,0,0.3);">{word_data['Word']}</h1>
            <hr style="border: 1px solid rgba(255,255,255,0.3);">
            <h2 style="margin: 0; font-size: 2em; text-shadow: 1px 1px 2px rgba(0,0,0,0.3);">{word_data['Meaning']}</h2>
        </div>
        """, unsafe_allow_html=True)
        
        # ìŒì„± ì¬ìƒ ë²„íŠ¼
        st.markdown("### ğŸ”Š ìŒì„± ë“£ê¸°")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ‡ºğŸ‡¸ ì˜ì–´ ë“£ê¸°", use_container_width=True, type="primary"):
                with st.spinner(f"ğŸ”Š '{word_data['Word']}' ìŒì„± ìƒì„± ì¤‘..."):
                    audio_bytes = generate_audio(word_data['Word'], 'en')
                    if audio_bytes:
                        st.audio(audio_bytes, format="audio/mp3")
        
        with col2:
            if st.button("ğŸ‡°ğŸ‡· í•œêµ­ì–´ ë“£ê¸°", use_container_width=True, type="primary"):
                with st.spinner(f"ğŸ”Š '{word_data['Meaning']}' ìŒì„± ìƒì„± ì¤‘..."):
                    audio_bytes = generate_audio(word_data['Meaning'], 'ko')
                    if audio_bytes:
                        st.audio(audio_bytes, format="audio/mp3")
        
        with col3:
            if st.button("ğŸµ ë‘˜ ë‹¤ ë“£ê¸°", use_container_width=True, type="secondary"):
                with st.spinner("ğŸ”Š ì˜ì–´ì™€ í•œêµ­ì–´ ìŒì„± ìƒì„± ì¤‘..."):
                    # ì˜ì–´ ë¨¼ì €
                    audio_en = generate_audio(word_data['Word'], 'en')
                    if audio_en:
                        st.write("ğŸ‡ºğŸ‡¸ ì˜ì–´:")
                        st.audio(audio_en, format="audio/mp3")
                    
                    # í•œêµ­ì–´
                    audio_ko = generate_audio(word_data['Meaning'], 'ko')
                    if audio_ko:
                        st.write("ğŸ‡°ğŸ‡· í•œêµ­ì–´:")
                        st.audio(audio_ko, format="audio/mp3")
        
        # ë„¤ë¹„ê²Œì´ì…˜ ë²„íŠ¼
        st.markdown("---")
        st.markdown("### ğŸ¯ í•™ìŠµ ë„¤ë¹„ê²Œì´ì…˜")
        nav_col1, nav_col2, nav_col3, nav_col4 = st.columns(4)
        
        with nav_col1:
            if st.button("â®ï¸ ì´ì „", disabled=(current_idx == 0), use_container_width=True):
                st.session_state.current_index = max(0, current_idx - 1)
                st.rerun()
        
        with nav_col2:
            if st.button("â­ï¸ ë‹¤ìŒ", disabled=(current_idx >= len(data) - 1), use_container_width=True):
                st.session_state.current_index = min(len(data) - 1, current_idx + 1)
                st.rerun()
        
        with nav_col3:
            if st.button("ğŸ”„ ì²˜ìŒë¶€í„°", use_container_width=True):
                st.session_state.current_index = 0
                st.rerun()
        
        with nav_col4:
            if st.button("ğŸ“Š ì™„ë£Œ!", use_container_width=True):
                st.balloons()
                st.success(f"ğŸ‰ í˜„ì¬ê¹Œì§€ {current_idx + 1}ê°œ ë‹¨ì–´ë¥¼ í•™ìŠµí–ˆìŠµë‹ˆë‹¤!")
                st.info(f"ì „ì²´ ì§„í–‰ë¥ : {progress*100:.1f}%")

    # ë‹¨ì–´ ëª©ë¡ í‘œì‹œ
    with st.expander("ğŸ“š ì „ì²´ ë‹¨ì–´ ëª©ë¡ ë³´ê¸°"):
        # ê²€ìƒ‰ ê¸°ëŠ¥ ì¶”ê°€
        search_term = st.text_input("ğŸ” ë‹¨ì–´ ê²€ìƒ‰:", placeholder="ê²€ìƒ‰í•  ì˜ì–´ ë‹¨ì–´ë‚˜ í•œêµ­ì–´ ëœ» ì…ë ¥")
        
        if search_term:
            filtered_data = data[
                data['Word'].str.contains(search_term, case=False, na=False) |
                data['Meaning'].str.contains(search_term, case=False, na=False)
            ]
            st.write(f"ê²€ìƒ‰ ê²°ê³¼: {len(filtered_data)}ê°œ")
            st.dataframe(filtered_data, use_container_width=True)
        else:
            st.dataframe(data, use_container_width=True)

else:
    # ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì•ˆë‚´
    st.markdown("""
    ## âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨
    
    êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
    
    ### ğŸ” í™•ì¸ì‚¬í•­:
    1. **êµ¬ê¸€ ì‹œíŠ¸ê°€ 'ì›¹ì— ê²Œì‹œ' ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸**
    2. **ì‹œíŠ¸ì˜ ì²« ë²ˆì§¸ í–‰ì´ 'Word', 'Meaning'ì¸ì§€ í™•ì¸**
    3. **ì¸í„°ë„· ì—°ê²° ìƒíƒœ í™•ì¸**
    
    ### ğŸ“‹ ì˜¬ë°”ë¥¸ êµ¬ê¸€ ì‹œíŠ¸ í˜•ì‹:
    
    | Word | Meaning |
    |------|---------|
    | apple | ì‚¬ê³¼ |
    | book | ì±… |
    | happy | í–‰ë³µí•œ |
    
    ### ğŸ”„ í•´ê²° ë°©ë²•:
    1. êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ **íŒŒì¼ â†’ ì›¹ì— ê²Œì‹œ** í´ë¦­
    2. **"ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ê°’(.csv)"** ì„ íƒ
    3. **ê²Œì‹œ** í´ë¦­
    4. ì™¼ìª½ ì‚¬ì´ë“œë°”ì˜ **"ë°ì´í„° ìƒˆë¡œê³ ì¹¨"** ë²„íŠ¼ í´ë¦­
    """)

st.markdown("---")
st.caption("ğŸš€ Powered by Streamlit + Google Sheets + AI | ìë™ ì—°ê²° ë²„ì „")

# í•˜ë‹¨ì— í˜„ì¬ ì„¤ì •ëœ ì‹œíŠ¸ URL í‘œì‹œ (ê°œë°œììš©)
with st.expander("ğŸ”§ ê°œë°œì ì •ë³´", expanded=False):
    st.code(f"GOOGLE_SHEET_URL = '{GOOGLE_SHEET_URL}'", language="python")
    st.caption("ğŸ’¡ ì‹œíŠ¸ ì£¼ì†Œë¥¼ ë³€ê²½í•˜ë ¤ë©´ ì½”ë“œì˜ GOOGLE_SHEET_URL ë³€ìˆ˜ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.")
